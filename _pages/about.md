---
permalink: /
title: "Research Areas"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
**Xiong Junwu** is dedicated to cutting-edge research on **scalable reinforcement learning (RL) and agentic alignment from AI to AGI,** aiming to bridge the gap between specialized artificial intelligence and general-purpose autonomous systems through ethical, scalable, and adaptive frameworks.

**Xiong Junwu** is currently advancing research on **scalable reinforcement learning methods** and **agentic alignment techniques** within **large language model (LLM) foundation models**, aiming to enhance their **complex reasoning capabilities**. His work focuses on developing advanced algorithms and frameworks that leverage high-quality data, including R1/O1-related scalable RL alignment algorithms, post-training methods such as **reinforcement learning with diverse feedbacks (RLXF)** and supervised fine-tuning (SFT), and broader AI alignment strategies. Additionally, he is actively involved in research on **multimodal interaction** and demonstrates a keen interest in **controllable AI-generated content (AIGC)**.

In his prior work, Xiong has made significant contributions to **reinforcement learning** and **multi-agent systems**, particularly through the development of **off-policy** and **on-policy RL algorithms and framework**, as well as algorithms for **cooperative** and **competitive multi-agent learning**. Furthermore, his research, which integrates **preference learning**, has been widely applied to practical domains such as **pricing**, **marketing**, and **recommendation systems**.
